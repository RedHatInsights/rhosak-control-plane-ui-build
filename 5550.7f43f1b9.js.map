{"version":3,"file":"5550.7f43f1b9.js","mappings":"iKAyBaA,EAAwB,SAAO,G,IAC1CC,EAAO,UACPC,EAAY,eACZC,EAAY,eACZC,EAAW,cACXC,EAAQ,W,kIASS,SAPG,IAAI,EAAAC,WACtB,IAAI,EAAAC,cAAc,CAChBH,YAAW,EACXC,SAAQ,KAIuBG,uBACjCP,EACAC,EACAC,EACA,CAAC,qC,OA0BH,OA9BMM,EAAW,SASXC,GAAiCD,EAASE,KAAKC,OAAS,IAAIC,QAChE,SAACC,GAEC,QACEA,EAAEC,QACFD,EAAEE,QACFF,EAAEE,OAAOC,OACTH,EAAEE,OAAOE,MACTJ,EAAEE,OAAOG,uBACTL,EAAEE,OAAOG,sBAAsBC,SAAS,iBAIxCC,EAAoC,GAE1CX,EAAYY,SAAQ,SAACR,GACnBA,EAAEC,OAAOO,SACP,SAAC,G,IAAEC,EAAK,QAAEC,EAAS,YACjB,OAACH,EAAeG,GAAaD,GAASF,EAAeG,IAAc,SAGlE,CAAP,EAAOH,WAIII,EAAqB,SAAOC,GAA8B,uD,mFACtC,SAAMC,QAAQC,IAAI,CAC/CC,EAAgB,CACdxB,SAAUqB,EAAMI,aAChB1B,YAAasB,EAAMtB,cAErB2B,EAAqBL,M,OAQvB,OAbM,EAAyB,SAAxBM,EAAW,KAAEC,EAAO,KAQjBC,EAIND,EAAO,OAHTE,EAGEF,EAAO,cAFTG,EAEEH,EAAO,cADTI,EACEJ,EAAO,kBACJ,CAAP,EAAO,CACLD,YAAW,EACXE,cAAa,EACbC,cAAa,EACbC,cAAa,EACbC,kBAAiB,YAIRR,EAAkB,SAAO,G,IACpCzB,EAAW,cACXC,EAAQ,W,oCAC2BsB,SAAO,W,iEAOzB,SANL,IAAI,EAAAW,UACd,IAAI,EAAA/B,cAAc,CAChBH,YAAW,EACXC,SAAQ,KAGekC,eACzBC,EACA,IACA,SACAA,OACAA,OACAA,OACAA,I,OAEF,MAAO,CAAP,GATiB,SASA7B,KAAKC,OAAS,IAAI6B,KAAI,SAACC,GAAM,OAAAA,EAAExB,iBAgB3C,SAAea,EAAqB,G,IACzC3B,EAAW,cACXC,EAAQ,WACRJ,EAAO,UACPC,EAAY,eACZC,EAAY,eACZwC,EAAa,gB,kCACiBhB,SAAO,W,qFAUpB,OATXiB,EAAgB,CAAC,qBAAsB,oBAS5B,GAPG,IAAI,EAAAtC,WACtB,IAAI,EAAAC,cAAc,CAChBH,YAAW,EACXC,SAAQ,KAIuBG,uBACjCP,EACAC,EACAC,EACA,CACE,iDACA,kDACA,wC,OA0DJ,OAjEMM,EAAW,SAaXC,GAAiCD,EAASE,KAAKC,OAAS,IAAIC,QAChE,SAACC,G,MAEC,QAAEA,EAAEC,QAAUD,EAAEE,QAAUF,EAAEE,OAAOC,OAASH,EAAEE,OAAOE,MACpD0B,EAAcxB,UAAiB,QAAR,EAAAN,EAAEE,cAAM,eAAEC,QAAS,QAIzC4B,EAAkBnC,EAAYG,QAAO,SAACC,GAAC,MAE3C,YAAkB0B,IAAlBG,IAAsC,QAAR,EAAA7B,EAAEE,cAAM,eAAEC,SAAU0B,KAI9CG,EAASC,MAAMC,KAAK,IAAIC,IAAIvC,EAAY+B,KAAI,SAAC3B,GAAM,OAAAA,EAAEE,OAAOC,WAE5DkB,EAAmC,GACnCC,EAAmC,GACnCC,EAA0C,GAEhDQ,EAAgBvB,SAAQ,SAACR,GACjB,IAUEoC,EAVF,EAA4BpC,EAAEE,OAAlBE,EAAI,WAAED,EAAK,QAE7B,SAASkC,EAA0BnC,GACjCF,EAAEC,OAAOO,SACP,SAAC,G,IAAEC,EAAK,QAAEC,EAAS,YACjB,OAACR,EAAOQ,GAAaD,GAASP,EAAOQ,IAAc,MAazD,OAAQN,GACN,IAAK,iDACHiC,EAA0BhB,GAC1B,MACF,IAAK,kDACHgB,EAA0Bf,GAC1B,MACF,IAAK,qCAfCc,EAAYb,EAAkBpB,IAAU,GAC9CH,EAAEC,OAAOO,SACP,SAAC,G,IAAEC,EAAK,QAAEC,EAAS,YACjB,OAAC0B,EAAU1B,GAAaD,GAAS2B,EAAU1B,IAAc,MAE7Da,EAAkBpB,GAASiC,MAgBxB,CAAP,EAAO,CACLJ,OAAM,EACNV,cAAa,EACbD,cAAa,EACbE,kBAAiB,a,uGClMrB,QAhBgE,SAAC,G,IAC/DpC,EAAO,UACPmD,EAAW,cACXC,EAAa,gBAEb,OACE,kBAAC,EAAAC,gBAAe,CAACC,MAAM,UACrB,kBAAC,IAAO,CACNtD,QAASA,EACTmD,YAAaA,EACbC,cAAeA","sources":["webpack://kas-ui/./src/app/modules/Metrics/MetricsApi.ts","webpack://kas-ui/./src/app/modules/Metrics/MetricsFederated.tsx"],"sourcesContent":["import { TopicsApi } from '@rhoas/kafka-instance-sdk';\nimport {\n  Configuration,\n  ConfigurationParameters,\n  DefaultApi,\n  RangeQuery,\n} from '@rhoas/kafka-management-sdk';\n\ntype NoUndefinedField<T> = {\n  [P in keyof T]-?: NoUndefinedField<NonNullable<T[P]>>;\n};\ntype SafeRangeQuery = NoUndefinedField<RangeQuery>;\nexport type TotalBytesMetrics = { [timestamp: string]: number };\nexport type PartitionBytesMetric = { [partition: string]: TotalBytesMetrics };\n\nexport type BasicApiConfigurationParameters = Pick<\n  ConfigurationParameters,\n  'accessToken' | 'basePath'\n>;\n\ntype FetchDiskSpaceMetricsProps = {\n  kafkaId: string;\n  timeDuration: number;\n  timeInterval: number;\n} & BasicApiConfigurationParameters;\nexport const fetchDiskSpaceMetrics = async ({\n  kafkaId,\n  timeDuration,\n  timeInterval,\n  accessToken,\n  basePath,\n}: FetchDiskSpaceMetricsProps) => {\n  const apisService = new DefaultApi(\n    new Configuration({\n      accessToken,\n      basePath,\n    })\n  );\n\n  const response = await apisService.getMetricsByRangeQuery(\n    kafkaId,\n    timeDuration,\n    timeInterval,\n    ['kubelet_volume_stats_used_bytes']\n  );\n\n  // Remove all results with no data. Not sure this can really  happen but since\n  // the types allow for undefined we need to do a bit of defensive programming.\n  const safeMetrics: SafeRangeQuery[] = (response.data.items || []).filter(\n    (m) =>\n      // defensive programming\n      !(\n        m.values &&\n        m.metric &&\n        m.metric.topic &&\n        m.metric.name &&\n        m.metric.persistentvolumeclaim &&\n        m.metric.persistentvolumeclaim.includes('zookeeper')\n      )\n  ) as SafeRangeQuery[];\n\n  const aggregatedData: TotalBytesMetrics = {};\n\n  safeMetrics.forEach((m) => {\n    m.values.forEach(\n      ({ value, timestamp }) =>\n        (aggregatedData[timestamp] = value + (aggregatedData[timestamp] || 0))\n    );\n  });\n  return aggregatedData;\n};\n\ntype FetchTopicsMetricsProps = FetchRawTopicsMetricsProps;\nexport const fetchTopicsMetrics = async (props: FetchTopicsMetricsProps) => {\n  const [kafkaTopics, metrics] = await Promise.all([\n    fetchKafkaTopis({\n      basePath: props.kafkaApiPath,\n      accessToken: props.accessToken,\n    }),\n    fetchRawTopicMetrics(props),\n  ]);\n  const {\n    topics: metricsTopics,\n    bytesIncoming,\n    bytesOutgoing,\n    bytesPerPartition,\n  } = metrics;\n  return {\n    kafkaTopics,\n    metricsTopics,\n    bytesIncoming,\n    bytesOutgoing,\n    bytesPerPartition,\n  };\n};\n\nexport const fetchKafkaTopis = async ({\n  accessToken,\n  basePath,\n}: BasicApiConfigurationParameters): Promise<string[]> => {\n  const api = new TopicsApi(\n    new Configuration({\n      accessToken,\n      basePath,\n    })\n  );\n  const response = await api.getTopics(\n    undefined,\n    100,\n    100,\n    undefined,\n    undefined,\n    undefined,\n    undefined\n  );\n  return (response.data.items || []).map((t) => t.name as string);\n};\n\ntype FetchRawTopicsMetricsProps = {\n  kafkaId: string;\n  kafkaApiPath: string;\n  timeDuration: number;\n  timeInterval: number;\n  selectedTopic: string | undefined;\n} & BasicApiConfigurationParameters;\ntype FetchRawTopicsMetricsReturnValue = {\n  topics: string[];\n  bytesOutgoing: TotalBytesMetrics;\n  bytesIncoming: TotalBytesMetrics;\n  bytesPerPartition: PartitionBytesMetric;\n};\nexport async function fetchRawTopicMetrics({\n  accessToken,\n  basePath,\n  kafkaId,\n  timeDuration,\n  timeInterval,\n  selectedTopic,\n}: FetchRawTopicsMetricsProps): Promise<FetchRawTopicsMetricsReturnValue> {\n  const privateTopics = ['__consumer_offsets', '__strimzi_canary'];\n\n  const apisService = new DefaultApi(\n    new Configuration({\n      accessToken,\n      basePath,\n    })\n  );\n\n  const response = await apisService.getMetricsByRangeQuery(\n    kafkaId,\n    timeDuration,\n    timeInterval,\n    [\n      'kafka_server_brokertopicmetrics_bytes_in_total',\n      'kafka_server_brokertopicmetrics_bytes_out_total',\n      'kafka_topic:kafka_log_log_size:sum',\n    ]\n  );\n\n  // Remove all results with no data. Not sure this can really  happen but since\n  // the types allow for undefined we need to do a bit of defensive programming.\n  const safeMetrics: SafeRangeQuery[] = (response.data.items || []).filter(\n    (m) =>\n      // defensive programming\n      !(m.values && m.metric && m.metric.topic && m.metric.name) &&\n      !privateTopics.includes(m.metric?.topic || '')\n  ) as SafeRangeQuery[];\n\n  // Also filter for metrics about the selectedTopic, if specified\n  const filteredMetrics = safeMetrics.filter((m) =>\n    // filter for metrics for the selectedTopic, if needed\n    selectedTopic !== undefined ? m.metric?.topic === selectedTopic : true\n  );\n\n  // get the unique topics we have metrics for in the selected time range\n  const topics = Array.from(new Set(safeMetrics.map((m) => m.metric.topic)));\n\n  const bytesIncoming: TotalBytesMetrics = {};\n  const bytesOutgoing: TotalBytesMetrics = {};\n  const bytesPerPartition: PartitionBytesMetric = {};\n\n  filteredMetrics.forEach((m) => {\n    const { __name__: name, topic } = m.metric;\n\n    function addAggregatedTotalBytesTo(metric: TotalBytesMetrics) {\n      m.values.forEach(\n        ({ value, timestamp }) =>\n          (metric[timestamp] = value + (metric[timestamp] || 0))\n      );\n    }\n\n    function addAggregatePartitionBytes() {\n      const partition = bytesPerPartition[topic] || {};\n      m.values.forEach(\n        ({ value, timestamp }) =>\n          (partition[timestamp] = value + (partition[timestamp] || 0))\n      );\n      bytesPerPartition[topic] = partition;\n    }\n\n    switch (name) {\n      case 'kafka_server_brokertopicmetrics_bytes_in_total':\n        addAggregatedTotalBytesTo(bytesIncoming);\n        break;\n      case 'kafka_server_brokertopicmetrics_bytes_out_total':\n        addAggregatedTotalBytesTo(bytesOutgoing);\n        break;\n      case 'kafka_topic:kafka_log_log_size:sum':\n        addAggregatePartitionBytes();\n        break;\n    }\n  });\n\n  return {\n    topics,\n    bytesOutgoing,\n    bytesIncoming,\n    bytesPerPartition,\n  };\n}\n","import React from 'react';\nimport { Metrics, MetricsProps } from '@app/modules/Metrics/Metrics';\nimport { initI18N } from '@i18n/i18n';\nimport { I18nextProvider } from 'react-i18next';\n\n// Version of Metrics for federation\n\nconst MetricsFederated: React.FunctionComponent<MetricsProps> = ({\n  kafkaId,\n  apiBasePath,\n  onCreateTopic,\n}) => {\n  return (\n    <I18nextProvider i18n={initI18N()}>\n      <Metrics\n        kafkaId={kafkaId}\n        apiBasePath={apiBasePath}\n        onCreateTopic={onCreateTopic}\n      />\n    </I18nextProvider>\n  );\n};\n\nexport default MetricsFederated;\n"],"names":["fetchDiskSpaceMetrics","kafkaId","timeDuration","timeInterval","accessToken","basePath","DefaultApi","Configuration","getMetricsByRangeQuery","response","safeMetrics","data","items","filter","m","values","metric","topic","name","persistentvolumeclaim","includes","aggregatedData","forEach","value","timestamp","fetchTopicsMetrics","props","Promise","all","fetchKafkaTopis","kafkaApiPath","fetchRawTopicMetrics","kafkaTopics","metrics","metricsTopics","bytesIncoming","bytesOutgoing","bytesPerPartition","TopicsApi","getTopics","undefined","map","t","selectedTopic","privateTopics","filteredMetrics","topics","Array","from","Set","partition","addAggregatedTotalBytesTo","apiBasePath","onCreateTopic","I18nextProvider","i18n"],"sourceRoot":""}